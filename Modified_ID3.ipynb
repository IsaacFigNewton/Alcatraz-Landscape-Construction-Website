{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrlfpktLzfBp+TVWhHzIre",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IsaacFigNewton/Alcatraz-Landscape-Construction-Website/blob/master/Modified_ID3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "ODb1tRW6rf0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score"
      ],
      "metadata": {
        "id": "KffJWkE0p4Uk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Important Functions\n",
        "\n",
        "Based on code from serengil's repository\n",
        "https://github.com/serengil/decision-trees-for-ml/tree/master"
      ],
      "metadata": {
        "id": "9S0vQ07LrV-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculateEntropy(df):\n",
        "    \"\"\"\n",
        "    Calculate the entropy of the given dataset.\n",
        "\n",
        "    Args:\n",
        "    df (pandas.DataFrame): The dataset containing the 'Decision' column.\n",
        "\n",
        "    Returns:\n",
        "    float: The calculated entropy value.\n",
        "    \"\"\"\n",
        "    instances = df.shape[0]\n",
        "    decisions = df['Decision'].value_counts().keys().tolist()\n",
        "    entropy = 0\n",
        "\n",
        "    for decision in decisions:\n",
        "        num_of_decisions = df['Decision'].value_counts()[decision]\n",
        "        class_probability = num_of_decisions / instances\n",
        "        entropy -= class_probability * np.log2(class_probability) if class_probability > 0 else 0\n",
        "\n",
        "    return entropy"
      ],
      "metadata": {
        "id": "Mr6KGKamrPXr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def findDecision(df):\n",
        "    \"\"\"\n",
        "    Find the best feature to split the dataset on using the ID3 algorithm.\n",
        "\n",
        "    Args:\n",
        "    df (pandas.DataFrame): The dataset to analyze.\n",
        "\n",
        "    Returns:\n",
        "    str: The name of the feature with the highest information gain.\n",
        "    \"\"\"\n",
        "    entropy = calculateEntropy(df)\n",
        "    columns = df.shape[1]\n",
        "    instances = df.shape[0]\n",
        "    gains = []\n",
        "\n",
        "    for i in range(columns - 1):\n",
        "        column_name = df.columns[i]\n",
        "        classes = df[column_name].value_counts()\n",
        "        gain = entropy\n",
        "\n",
        "        for current_class in classes.keys():\n",
        "            subdataset = df[df[column_name] == current_class]\n",
        "            subset_instances = subdataset.shape[0]\n",
        "            class_probability = subset_instances / instances\n",
        "            subset_entropy = calculateEntropy(subdataset)\n",
        "            gain -= class_probability * subset_entropy\n",
        "\n",
        "        gains.append(gain)\n",
        "\n",
        "    winner_index = gains.index(max(gains))\n",
        "    winner_name = df.columns[winner_index]\n",
        "    return winner_name"
      ],
      "metadata": {
        "id": "LnUJgOLxrRXD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MVmY98NqpyIO"
      },
      "outputs": [],
      "source": [
        "def buildDecisionTree(df):\n",
        "    \"\"\"\n",
        "    Recursively build the ID3 decision tree.\n",
        "\n",
        "    Args:\n",
        "    df (pandas.DataFrame): The dataset to build the tree from.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary representing the decision tree.\n",
        "    \"\"\"\n",
        "    if len(df['Decision'].unique()) == 1:\n",
        "        return df['Decision'].iloc[0]\n",
        "\n",
        "    if df.shape[1] == 1:\n",
        "        return df['Decision'].value_counts().idxmax()\n",
        "\n",
        "    winner_name = findDecision(df)\n",
        "    tree = {winner_name: {}}\n",
        "\n",
        "    for current_class in df[winner_name].unique():\n",
        "        subdataset = df[df[winner_name] == current_class].drop(columns=[winner_name])\n",
        "        tree[winner_name][current_class] = buildDecisionTree(subdataset)\n",
        "\n",
        "    return tree"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(tree, instance):\n",
        "    \"\"\"\n",
        "    Make a prediction for a single instance using the decision tree.\n",
        "\n",
        "    Args:\n",
        "    tree (dict): The decision tree.\n",
        "    instance (pandas.Series): A single instance to classify.\n",
        "\n",
        "    Returns:\n",
        "    str: The predicted class.\n",
        "    \"\"\"\n",
        "    if not isinstance(tree, dict):\n",
        "        return tree\n",
        "\n",
        "    root = list(tree.keys())[0]\n",
        "    if instance[root] in tree[root]:\n",
        "        return predict(tree[root][instance[root]], instance)\n",
        "    else:\n",
        "        # If the value is not in the tree, return the most common class\n",
        "        return max(tree[root], key=lambda x: len(tree[root][x]))"
      ],
      "metadata": {
        "id": "DL-hjayEp08z"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_tree(tree, indent=0):\n",
        "    for key, value in tree.items():\n",
        "        print(' ' * indent + str(key))\n",
        "        if isinstance(value, dict):\n",
        "            print_tree(value, indent + 4)\n",
        "        else:\n",
        "            print(' ' * (indent + 4) + str(value))"
      ],
      "metadata": {
        "id": "Ack2q-2n2Qma"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run code"
      ],
      "metadata": {
        "id": "4pIKqI8LrcK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/serengil/decision-trees-for-ml/master/dataset/golf.txt\")\n",
        "\n",
        "# Prepare for k-fold cross-validation\n",
        "k = 5\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "# Lists to store evaluation metrics\n",
        "precisions, recalls, accuracies, f1_scores = [], [], [], []\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(df), 1):\n",
        "    print(f\"Fold {fold}\")\n",
        "\n",
        "    # Split the data\n",
        "    train_data = df.iloc[train_index]\n",
        "    test_data = df.iloc[test_index]\n",
        "\n",
        "    # Build the decision tree\n",
        "    tree = buildDecisionTree(train_data)\n",
        "\n",
        "    # Print the decision tree\n",
        "    print_tree(tree)\n",
        "    print()\n",
        "\n",
        "    # Make predictions\n",
        "    y_true = test_data['Decision']\n",
        "    y_pred = test_data.apply(lambda x: predict(tree, x), axis=1)\n",
        "\n",
        "    # Calculate metrics using sklearn\n",
        "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    accuracies.append(accuracy)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print()\n",
        "\n",
        "# Print average scores\n",
        "print()\n",
        "print(\"Average Scores:\")\n",
        "print(f\"Precision: {np.mean(precisions):.4f} (+/- {np.std(precisions):.4f})\")\n",
        "print(f\"Recall: {np.mean(recalls):.4f} (+/- {np.std(recalls):.4f})\")\n",
        "print(f\"Accuracy: {np.mean(accuracies):.4f} (+/- {np.std(accuracies):.4f})\")\n",
        "print(f\"F1 Score: {np.mean(f1_scores):.4f} (+/- {np.std(f1_scores):.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uyBkByUrAdb",
        "outputId": "4c4e2962-6ffc-4175-8c54-fbcb0af0e364"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n",
            "Outlook\n",
            "    Sunny\n",
            "        Humidity\n",
            "            High\n",
            "                No\n",
            "            Normal\n",
            "                Yes\n",
            "    Overcast\n",
            "        Yes\n",
            "    Rain\n",
            "        Wind\n",
            "            Weak\n",
            "                Yes\n",
            "            Strong\n",
            "                No\n",
            "\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "Accuracy: 1.0000\n",
            "F1 Score: 1.0000\n",
            "\n",
            "Fold 2\n",
            "Outlook\n",
            "    Sunny\n",
            "        Humidity\n",
            "            High\n",
            "                No\n",
            "            Normal\n",
            "                Yes\n",
            "    Overcast\n",
            "        Yes\n",
            "    Rain\n",
            "        Wind\n",
            "            Weak\n",
            "                Yes\n",
            "            Strong\n",
            "                No\n",
            "\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "Accuracy: 1.0000\n",
            "F1 Score: 1.0000\n",
            "\n",
            "Fold 3\n",
            "Outlook\n",
            "    Sunny\n",
            "        Humidity\n",
            "            High\n",
            "                No\n",
            "            Normal\n",
            "                Yes\n",
            "    Rain\n",
            "        Wind\n",
            "            Weak\n",
            "                Yes\n",
            "            Strong\n",
            "                No\n",
            "    Overcast\n",
            "        Yes\n",
            "\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "Accuracy: 1.0000\n",
            "F1 Score: 1.0000\n",
            "\n",
            "Fold 4\n",
            "Outlook\n",
            "    Sunny\n",
            "        Temp.\n",
            "            Hot\n",
            "                No\n",
            "            Cool\n",
            "                Yes\n",
            "    Overcast\n",
            "        Yes\n",
            "    Rain\n",
            "        Wind\n",
            "            Weak\n",
            "                Yes\n",
            "            Strong\n",
            "                No\n",
            "\n",
            "Precision: 0.6667\n",
            "Recall: 0.3333\n",
            "Accuracy: 0.3333\n",
            "F1 Score: 0.4444\n",
            "\n",
            "Fold 5\n",
            "Outlook\n",
            "    Sunny\n",
            "        Humidity\n",
            "            High\n",
            "                No\n",
            "            Normal\n",
            "                Yes\n",
            "    Overcast\n",
            "        Yes\n",
            "    Rain\n",
            "        Wind\n",
            "            Weak\n",
            "                Yes\n",
            "            Strong\n",
            "                No\n",
            "\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "Accuracy: 1.0000\n",
            "F1 Score: 1.0000\n",
            "\n",
            "\n",
            "Average Scores:\n",
            "Precision: 0.9333 (+/- 0.1333)\n",
            "Recall: 0.8667 (+/- 0.2667)\n",
            "Accuracy: 0.8667 (+/- 0.2667)\n",
            "F1 Score: 0.8889 (+/- 0.2222)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eViSsQPfykZy"
      },
      "execution_count": 42,
      "outputs": []
    }
  ]
}